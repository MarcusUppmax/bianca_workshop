{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p> <p></p> <p></p> <p></p>"},{"location":"#welcome-to-the-bianca-workshop","title":"Welcome to the Bianca workshop","text":"<p>Introduction to Bianca: Handling Sensitive Research Data</p> <ul> <li>Are you working with your sensitive data in your research? </li> <li>If yes, welcome to a full day introduction to handling sensitive data on the UPPMAX cluster, Bianca. </li> <li> <p>We will tell you about </p> <ul> <li>NAISS-SENS, </li> <li>how to login to Bianca, </li> <li>transfer files via wharf, </li> <li>Slurm and the module system, </li> <li>and how to work with Conda packages.</li> </ul> </li> <li> <p>You do not need to be a member of a NAISS-SENS project in order to join the workshop. </p> <ul> <li>A SUPR course project will be available to all participants. The workshop will consist of both lectures and exercise sessions.</li> </ul> </li> <li> <p>When: March 15, 2023.</p> </li> <li> <p>Where: online via Zoom.</p> </li> <li> <p>For more information and registration please visit: https://www.uppmax.uu.se/support/courses-and-workshops/bianca-workshop-2023.</p> </li> </ul> <p>"},{"location":"#schedule","title":"Schedule","text":"Topic Start Timing Content Syllabus and intro 9.00 10 intro Login 9.10 50 login ssh/ThinLinc, 2FA Coffee break 10.00 15 Break Working with the command-line 10.15 30 Command-line intro Module system 10.45 20 Module system Short break 11.05 5 Break Transferring files 11.10 50 Transfering files to/from Bianca LUNCH break 12.00 60 NAISS-SENS and sensitive data 13.00 60 NAISS-SENS and sensitive data Short break 14.00 5 Break Module system (cont.) and SLURM 14.05 20 Module system (cont.) and SLURM Software installation without internet connection 14.25 15 Software installation without internet connection Summary 14.40 10 Summary Coffee break 14.50 15 Break Q/A 15.05 55 Time for interaction <p>Get started using Bianca</p> <p></p> <p></p>"},{"location":"conda/","title":"Conda","text":"<p>Objectives</p> <ul> <li>We'll ...</li> </ul> <p>keypoints</p> <ul> <li>bullet 1</li> <li>bullet 2</li> </ul>"},{"location":"containers/","title":"Using containers on Bianca","text":"<p>Objectives</p> <ul> <li>We'll ...</li> </ul> <p>keypoints</p> <ul> <li>bullet 1</li> <li>bullet 2</li> </ul>"},{"location":"install/","title":"Software installation without internet connection","text":"<p>To be removed</p> <pre><code>- Conda packages: installing/using [name=Jonas]\n    - alternative: installing with pip\n- R package installation not included in R packages [name=Marcus]\n- Julia [name=Bj\u00f6rn C]\n- running jupyter notebooks [name=Lars]\n- containers [name=Bj\u00f6rn V]\n</code></pre>"},{"location":"install/#install-software-yourself","title":"Install software yourself","text":"<ul> <li>You can install in your home directory.<ul> <li>This is handy for personal needs, low numbers of files (i.e. not Conda).</li> </ul> </li> <li>Usually better to install in project directory.<ul> <li>This way the project contains both data and software \u2014 good for reproducibility, collaboration, and everyone's general sanity.</li> </ul> </li> <li>If not available on Bianca already you may have to use the Wharf to insatll your tools<ul> <li>alternatively let a Application Expert install the tool as a module.</li> </ul> </li> </ul>"},{"location":"install/#python-packages","title":"Python packages","text":"<ul> <li>Python packages</li> </ul>"},{"location":"install/#conda","title":"Conda","text":"<ul> <li>Conda user guide</li> </ul>"},{"location":"install/#containers","title":"\"Containers\"","text":""},{"location":"install/#singularity","title":"Singularity","text":"<ul> <li>Singularity user guide</li> </ul>"},{"location":"install/#docker","title":"Docker","text":"<ul> <li>Docker will unfortunately not work on the clusters, since it requires root permission.</li> </ul>"},{"location":"install/#build-from-source","title":"Build from source","text":"<ul> <li>We have several compiler versions from GNU and INTEL</li> <li>Guide for compiling serial and parallel programs</li> </ul>"},{"location":"install/#spack","title":"Spack","text":"<ul> <li>The UPPMAX staff has already other ways to install most software applications. </li> <li>Please use Spack only if other ways to install your tool is not possible or very difficult, e.g. requiring very many dependencies and it is not available through, e.g. Easybuild.</li> <li>Spack user guide at UPPMAX</li> </ul>"},{"location":"install/#own-development","title":"Own development...","text":"<ul> <li>You may have your own code that you want to run on UPPMAX.</li> <li>See the guide for compiling serial and parallel programs</li> <li>User guide for debuggers and profilers</li> </ul>"},{"location":"install/#run-own-scripts-or-programs","title":"Run own scripts or programs","text":"<ul> <li>Unless your script or program is in the active path, you run it by the full path or <code>./&lt;file&gt;</code> if you are in the present directory.</li> </ul> <p>Keypoints</p> <ul> <li>Centrally installed software are reached through the module system and available throughout all nodes.</li> <li>Your own installed software, scripts, python packages etcetera are available from their paths.</li> </ul>"},{"location":"julia/","title":"Using Julia packages on Bianca","text":"<p>Objectives</p> <ul> <li>We'll ...</li> </ul> <p>keypoints</p> <ul> <li>bullet 1</li> <li>bullet 2</li> </ul>"},{"location":"jupyter/","title":"Running Jupyter on Bianca","text":"<p>Objectives</p> <ul> <li>We'll ...</li> </ul> <p>keypoints</p> <ul> <li>bullet 1</li> <li>bullet 2</li> </ul>"},{"location":"linux/","title":"Command-line intro","text":"<p>Objectives</p> <ul> <li>We'll use the commands and investigate the Bianca environment</li> </ul> <p>Warning</p> <ul> <li>We assume that you have already covered the Command-line material and tested on Rackham<ul> <li>LINUX</li> <li>Basic toolkit</li> </ul> </li> </ul> <p>### Navigation and file management</p> <ol> <li><code>pwd</code>  \u2003 present directory</li> <li><code>ls</code>  \u2003list content</li> <li><code>cd</code>  \u2003change directory</li> <li><code>mkdir</code>  \u2003make directory</li> <li><code>cp</code>  \u2003copy</li> <li><code>scp</code>  \u2003securely remotely copy</li> <li><code>mv</code>  \u2003move</li> <li><code>rm</code>  \u2003remove</li> <li><code>rmdir</code>  \u2003remove empty directory</li> </ol>"},{"location":"linux/#read-files-and-change-file-properties","title":"Read files and change file properties","text":"<ol> <li><code>cat</code>  \u2003print content on screen</li> <li><code>head</code>  \u2003print first part</li> <li><code>tail</code>  \u2003print last part</li> <li><code>less</code>  \u2003browse content</li> <li><code>tar</code>  \u2003compress or extract file</li> <li><code>chmod</code>  \u2003change file permissions</li> <li><code>man</code>  \u2003info about a command</li> </ol>"},{"location":"linux/#type-along","title":"Type along","text":""},{"location":"linux/#navigating-bianca","title":"Navigating Bianca","text":"<ul> <li>Check the path to your $HOME folder</li> </ul> <pre><code>$ cd ~\n$ pwd\n$ pwd -P\n</code></pre> Answer <pre><code>/home/$USER\n/castor/project/home/bjornc\n</code></pre> <ul> <li>Check the path to your projects</li> </ul> <pre><code>$ cd /proj\n$ ls\n$ pwd\n$ pwd -P\n</code></pre> Answer <pre><code>/proj\n/proj\n</code></pre> <pre><code>$ cd /sensXXX\n$ pwd\n$ pwd -P\n</code></pre> Answer <pre><code>/proj/sensXXX\n/castor/project/proj\n</code></pre>"},{"location":"login_bianca/","title":"Log in to Bianca","text":"<p>Objectives</p> <ul> <li>We'll go through the methods to log in</li> </ul> <p>Note</p> <ul> <li>Remember that Rackham is your friend as well in your work. </li> <li>Being able to work there as well will improve your possibilities to work effectively when you also need some sort of internet connection. For instance:</li> <li>installing tools</li> <li>installing Python, R and Julia packages</li> <li>transfer scripts</li> <li>updating your git repositories (not containing sensitive data)</li> </ul>"},{"location":"login_bianca/#biancas-design","title":"Bianca's design","text":"<ul> <li>Bianca was designed<ul> <li>to make accidental data leaks difficult</li> <li>to make correct data management as easy as possible</li> <li>to emulate the HPC cluster environment that SNIC users were familiar with</li> <li>to provide a maximum amount of resources</li> <li>and to satisfy regulations.</li> </ul> </li> </ul> <p>Bianca has no internet</p> <ul> <li>Still you can log in, but it is done in two steps!</li> <li>We recomend the ThinLink web portal, to enable graphics</li> </ul>"},{"location":"login_bianca/#log-in-to-bianca-with-thinlinc","title":"Log in to Bianca with ThinLinc","text":"<ul> <li>Bianca offers graphical login<ul> <li>You need to be on SUNET or use VPN</li> <li>On web:<ul> <li>https://bianca.uppmax.uu.se</li> <li>requires 2-factor authentication</li> </ul> </li> </ul> </li> </ul>"},{"location":"login_bianca/#the-log-in-steps","title":"The log in steps","text":"<ol> <li>When you log in to https://bianca.uppmax.uu.se, your SSH or ThinLinc client first meets the blue Bianca login node.<ul> <li>user name: <code>&lt;username&gt;-&lt;projid&gt;@bianca.uppmax.uu.se</code><ul> <li>like: <code>myname-sens2016999@bianca.uppmax.uu.se</code></li> </ul> </li> <li>password: your password, directly followed by the 6-digit 2-factor<ul> <li>like: verysecret678123</li> </ul> </li> </ul> </li> <li>After checking your [2-factor authentication] this server looks for your virtual project cluster.</li> <li>If it's present, then you are transferred to a login prompt on your cluster's login node. If not, then the virtual cluster is started.<ul> <li>you are prompted to give your username and password again, this time without projid and 2nd-factor:<ul> <li>username:  <li>password: verysecret</li> <li>Inside each virtual project cluster, by default there is just a one-core login node. When you need more memory or more CPU power, you submit a job (interactive or batch), and an idle node will be moved into your project cluster.</li>"},{"location":"login_bianca/#bianca-has-no-internet","title":"Bianca has no Internet","text":"<p>... but we have \u201csolutions\u201d</p> <p></p> <ul> <li>Bianca is only accessible from within Sunet (i.e. from university networks).</li> <li>Use VPN outside Sunet. Link to VPN for UU</li> <li>You can get VPN credentials from all Swedish universities.</li> </ul> <p></p> <ul> <li>The whole Bianca cluster (blue) contains hundreds of virtual project clusters (green), each of which is isolated from each other and the Internet.</li> <li>Data can be transferred to or from a virtual project cluster through the Wharf, which is a special file area that is visible from the Internet.</li> </ul> <p>keypoints</p> <ul> <li>We recommend you to use ThinLinc to log in.</li> </ul>"},{"location":"modules1/","title":"Working with the modules on Bianca","text":"<p>Objectives</p> <ul> <li>We'll go through the methods to work with the modules</li> <li>We'll go through some typical workflows</li> </ul> <ul> <li>800+ programs and packages are installed.</li> <li>To avoid chaos and collisions, they are managed by a module system.</li> <li>This system keeps installed software hidden by default, and users have to explicitly tell their terminal which version of which software they need.</li> <li>The modules are most often available across cluster (except for Miarka)</li> </ul> <p>Warning</p> <ul> <li>Bioinformatics tools require loading the \u201cbioinfo-tools\u201d module first.</li> </ul>"},{"location":"modules1/#modules","title":"Modules","text":"<ul> <li>Software at UPPMAX</li> <li>Module system</li> </ul>"},{"location":"modules1/#some-commands","title":"Some commands","text":"<ul> <li> <p>list all available modules (also bio-informatics if <code>bioinfo-tools</code> is loaded)</p> <ul> <li><code>module avail</code> or <code>ml av</code></li> </ul> </li> <li> <p>Search for modules (full name not needed and case insensitive) </p> <ul> <li><code>module avail &lt;part of tool name&gt;</code> or <code>ml av &lt;part of toolname&gt;</code></li> </ul> </li> <li> <p>Load a module </p> <ul> <li><code>module load &lt;module name&gt;</code> or <code>ml &lt;module name&gt;</code></li> </ul> </li> <li> <p>Unload a module </p> <ul> <li><code>module unload &lt;module name&gt;</code> or <code>ml -&lt;module name&gt;</code></li> </ul> </li> <li> <p>List loaded modules </p> <ul> <li><code>module list</code> or <code>ml</code></li> </ul> </li> <li> <p>Display a brief module-specific help (not available for all modules)</p> <ul> <li><code>module help &lt;module name&gt;</code> or <code>ml help &lt;module name&gt;</code> </li> </ul> </li> <li> <p>Search (like <code>avail</code>) but otherwise hidden modules (<code>bioinfo-tools</code> and Easybuild modules) </p> <ul> <li><code>module spider &lt;part of tool name&gt;</code> or <code>ml spider &lt;module name&gt;</code> </li> </ul> </li> </ul>"},{"location":"modules1/#installed-software","title":"Installed software","text":"<ul> <li>You can also find (almost) all installed software at:<ul> <li>https://www.uppmax.uu.se/resources/software/installed-software/</li> </ul> </li> </ul>"},{"location":"modules1/#installed-databases","title":"Installed databases","text":"<ul> <li>Installed databases at UPPMAX</li> </ul>"},{"location":"modules1/#workflows","title":"Workflows","text":"<pre><code>- how to interact with R packages / R studio\n    - do demos in Thinlinc\n- gatk, vep, snipf, conda (loading only)\n</code></pre> <p>Change this example </p> Hands on using a tool\" <ol> <li>use matlab</li> </ol> <p><pre><code>$ matlab &amp;\n</code></pre> - Does not work! - Load module first <pre><code>$ module avail matlab\n\n$ module load matlab/R2020b\n\n$ matlab &amp;\n</code></pre> - Matlab starts - <code>module load matlab</code> will start default version (often latest)</p> <ol> <li>use Samtools</li> </ol> <p><pre><code>$ module load samtools\n</code></pre> \"These module(s) or extension(s) exist but cannot be loaded as requested: \"samtools\"\" <pre><code>module load bioinfo-tools samtools\n</code></pre> - Bioinformatic tools are hidden by default</p>"},{"location":"modules1/#r","title":"R","text":""},{"location":"modules1/#gatk","title":"GATK","text":""},{"location":"modules1/#snipf","title":"SNIPF","text":""},{"location":"modules1/#conda","title":"Conda","text":"<ul> <li>just loading procedure</li> <li>more in afternoon</li> </ul> <p>To extend</p> <p>keypoints</p> <ul> <li>Centrally installed software are reached through the module system and available throughout all nodes. </li> <li>Your own installed software, scripts, python packages etcetera are available from their paths.</li> </ul>"},{"location":"naiss-sens-bianca/","title":"NAISS-SENS, sensitive data and Bianca","text":"<p>Objectives</p> <ul> <li>We'll briefly get an overview of kinds of sensitive data</li> <li>... and the Bianca system</li> </ul> <p>Content (To remove later)</p> <pre><code>- extended from intro course \n- what is sensitive data?\n- puba &amp; timelines\n- how to apply for projects\n- project management\n- LINK to extra material\n- contact persons\n</code></pre>"},{"location":"naiss-sens-bianca/#sensitive-personal-data","title":"Sensitive personal data","text":"<ul> <li>https://www.snic.se/allocations/snic-sens/</li> <li>Traced to now living persons, e.g.<ul> <li>human genomic data</li> <li>images/videos containing persons</li> <li>health registry (health data records from healthcare providers)</li> </ul> </li> <li> <p>More about sensitive data</p> <ul> <li>GDPR</li> <li>Data protection</li> <li>Skydd av personuppgifter</li> </ul> </li> <li> <p>When in doubt, contact your university's data protection officer.</p> </li> <li>Generally, there must be a Data Processing Agreement between UU and the data controlling university.</li> </ul>"},{"location":"naiss-sens-bianca/#apply-for-project","title":"Apply for project","text":"<p>Open NAISS SENS Rounds</p>"},{"location":"naiss-sens-bianca/#bianca","title":"Bianca","text":"<ul> <li>Bianca is a great platform for computationally intensive research on sensitive personal data. It can also be useful for:<ul> <li>national and international collaboration on sensitive personal data (without a high compute need)</li> <li>other types of sensitive data</li> </ul> </li> <li>Bianca is not good for:<ul> <li>storing data</li> <li>publishing data<ul> <li>unless the dataset is very popular among Bianca users, e.g. Swegen, SIMPLER</li> </ul> </li> </ul> </li> </ul>"},{"location":"naiss-sens-bianca/#biancas-design","title":"Bianca's design","text":"<ul> <li>Bianca was designed<ul> <li>to make accidental data leaks difficult</li> <li>to make correct data management as easy as possible</li> <li>to emulate the HPC cluster environment that SNIC/NAISS users were familiar with</li> <li>to provide a maximum amount of resources</li> <li>and to satisfy regulations.</li> </ul> </li> </ul>"},{"location":"naiss-sens-bianca/#bianca-has-no-internet","title":"Bianca has no Internet","text":"<p>... but we have \u201csolutions\u201d</p> <p></p> <ul> <li>Bianca is only accessible from within Sunet (i.e. from university networks).</li> <li>Use VPN outside Sunet. Link to VPN for UU<ul> <li>You can get VPN credentials from all Swedish universities.</li> </ul> </li> </ul> <p></p> <ul> <li>The whole Bianca cluster (blue) contains hundreds of virtual project clusters (green), each of which is isolated from each other and the Internet.</li> <li>Data can be transferred to or from a virtual project cluster through the Wharf, which is a special file area that is visible from the Internet.</li> </ul> <p>keypoints</p> <ul> <li>bullet 1</li> <li>bullet 2</li> </ul>"},{"location":"overview/","title":"Overview","text":"<p>Objectives</p> <ul> <li>We'll get an overview of UPPMAX and SNIC/NAISS and how a computer cluster works</li> </ul> <p>UPPMAX = UppMACS - Uppsala Multidisciplinary Center for Advanced Computational Science</p>"},{"location":"overview/#naiss","title":"NAISS","text":"<ul> <li>National Academic Infrastructure for Supercomputing in Sweden</li> <li> <p>Mission: to provide a quality high-performance computing environment nationally</p> </li> <li> <p>Starting 1 January 2023, the National Academic Infrastructure for Supercomputing in Sweden (NAISS) is the new organization for high-performance computing, storage, and date services for academic users in Sweden. </p> </li> <li>From the users perspective, there will initially only be minimal differences between the SNIC and NAISS regimes.<ul> <li>FAQ:s \u2014 https://www.naiss.se/</li> </ul> </li> <li>Application rounds: https://www.naiss.se//#application-rounds-for-compute-and-storage-resources</li> <li>NAISS and Uppsala University fund UPPMAX \u2014 UU\u2019s supercomputing center.</li> </ul>"},{"location":"overview/#uppmax-missions","title":"UPPMAX missions","text":"<ul> <li>Runs the clusters placed in Uppsala.</li> <li>More details in the afternoon about Organisational orienteering!</li> </ul>"},{"location":"overview/#uppmax-systems","title":"UPPMAX systems","text":"<ul> <li>Clusters<ul> <li>Rackham (general purpose)<ul> <li>Snowy (Long runs and GPU:s)</li> </ul> </li> <li>Bianca (sensitive data)<ul> <li>Miarka (new for LifeScience)</li> </ul> </li> </ul> </li> <li>Storage<ul> <li>On-load directly connected to the clusters</li> <li>Off-load for large data not needed for computation analysis anymore</li> </ul> </li> <li>Cloud<ul> <li>Dis (region EAST-1)</li> </ul> </li> </ul>"},{"location":"overview/#high-performance-computing-hpc","title":"High Performance Computing \u2014 HPC","text":""},{"location":"overview/#what-is-a-cluster","title":"What is a cluster?","text":"<ul> <li> <p>A network of computers, each computer working as a node.</p> </li> <li> <p>From small scale RaspberryPi cluster... </p> </li> </ul> <p></p> <ul> <li>To supercomputers like Rackham.</li> </ul> <p></p> <ul> <li>Each node contains several processor cores and RAM and a local disk called scratch.</li> </ul> <p></p> <ul> <li> <p>The user logs in to login nodes  via Internet through ssh or Thinlinc.</p> </li> <li> <p>Here the file management and lighter data analysis can be performed.</p> </li> </ul> <p></p> <p></p> <ul> <li>The calculation nodes have to be used for intense computing. </li> </ul>"},{"location":"overview/#overview-of-the-uppmax-systems","title":"Overview of the UPPMAX systems","text":"<pre><code>\n  graph TB\n\n  Node1 -- interactive --&gt; SubGraph2Flow\n  Node1 -- sbatch --&gt; SubGraph2Flow\n  subgraph \"Snowy\"\n  SubGraph2Flow(calculation nodes) \n        end\n\n        thinlinc -- usr-sensXXX + 2FA----&gt; SubGraph1Flow\n        Node1 -- usr-sensXXX + 2FA----&gt; SubGraph1Flow\n        subgraph \"Bianca\"\n        SubGraph1Flow(Bianca login) -- usr+passwd --&gt; private(private cluster)\n        private -- interactive --&gt; calcB(calculation nodes)\n        private -- sbatch --&gt; calcB\n        end\n\n        subgraph \"Rackham\"\n        Node1[Login] -- interactive --&gt; Node2[calculation nodes]\n        Node1 -- sbatch --&gt; Node2\n        end</code></pre> <p>keypoints</p> <ul> <li>NAISS makes available large-scale high-performance computing resources, storage capacity, and advanced user support, for Swedish research. </li> <li>UPPMAX runs the local resources placed at Uppsala Universty</li> <li>A cluster consists of several inter-connected computers that can work individually or together.</li> </ul>"},{"location":"pip/","title":"Install with pip to Bianca","text":"<p>Objectives</p> <ul> <li>We'll ...</li> </ul> <p>keypoints</p> <ul> <li>bullet 1</li> <li>bullet 2</li> </ul>"},{"location":"practicalities/","title":"Practicalities","text":""},{"location":"practicalities/#prerequisities","title":"Prerequisities","text":"<ul> <li>SUPR/course project</li> <li>set up 2FA</li> <li> <p>need to have access to univ network or set up VPN</p> <ul> <li>/access via Rackham</li> </ul> </li> <li> <p>mention that getting an acoount and setting up 2FA may take several days</p> </li> <li> <p>detailed schedule - emphasize that it is OK to take parts of the course only</p> </li> <li> <p>1st day of the intro course, 1/2-1 day at your own pace, beneficial to do before the workshop</p> <ul> <li>https://uppmax.github.io/uppmax_intro/linux.html</li> <li>https://uppmax.github.io/uppmax_intro/linux_basics.html</li> </ul> </li> </ul>"},{"location":"rpackages/","title":"Installing R packages on Bianca","text":"<p>Objectives</p> <ul> <li>We'll ...</li> </ul> <p>keypoints</p> <ul> <li>bullet 1</li> <li>bullet 2</li> </ul>"},{"location":"slurm-intro/","title":"Introduction to compute nodes","text":"<p>To be removed later</p> <pre><code>- interactive vs. non-interactive sessions\n- why is interactive needed at all?\n- **e.g. nextflow - main node should be on interactive**\n</code></pre>"},{"location":"slurm-intro/#submitting-jobs","title":"Submitting jobs","text":"<p>Objectives</p> <ul> <li>This is a short introduction in how to reach the calculation nodes</li> </ul>"},{"location":"slurm-intro/#slurm-sbatch-the-job-queue","title":"Slurm, sbatch, the job queue","text":"<ul> <li> <p>Problem: 1000 users, 500 nodes, 10k cores</p> <ul> <li>Need a queue:</li> </ul> </li> <li> <p>Slurm is a jobs scheduler</p> </li> <li> <p>Plan your job and but in the slurm job batch (sbatch)</p> <ul> <li><code>sbatch &lt;flags&gt; &lt;program&gt;</code> or  <code>sbatch &lt;job script&gt;</code></li> </ul> </li> </ul>"},{"location":"slurm-intro/#jobs","title":"Jobs","text":"<ul> <li>Job = what happens during booked time</li> <li>Described in a Bash script file<ul> <li>Slurm parameters (flags)</li> <li>Load software modules</li> <li>(Move around file system)</li> <li>Run programs</li> <li>(Collect output)</li> </ul> </li> <li>... and more</li> </ul>"},{"location":"slurm-intro/#slurm-parameters","title":"Slurm parameters","text":"<ul> <li>1 mandatory setting for jobs:<ul> <li>Which compute project? (<code>-A</code>)</li> </ul> </li> <li>3 settings you really should set:<ul> <li>Type of queue? (<code>-p</code>)<ul> <li>core, node, (for short development jobs and tests: devcore, devel)</li> </ul> </li> <li>How many cores? (<code>-n</code>)<ul> <li>up to 16 (20 on Rackham) for core job</li> </ul> </li> <li>How long at most? (<code>-t</code>)</li> </ul> </li> <li>If in doubt:<ul> <li><code>-p core</code></li> <li><code>-n 1</code></li> <li><code>-t 7-00:00:00</code></li> </ul> </li> </ul> <ul> <li>Where should it run? (<code>-p node</code> or <code>-p core</code>)</li> <li>Use a whole node or just part of it?<ul> <li>1 node = 20 cores (16 on Bianca &amp; Snowy)</li> <li>1 hour walltime = 20 core hours = expensive<ul> <li>Waste of resources unless you have a parallel program or need all the memory, e.g. 128 GB per node</li> </ul> </li> </ul> </li> <li>Default value: core</li> </ul>"},{"location":"slurm-intro/#interactive-jobs","title":"Interactive jobs","text":"<ul> <li>Most work is most effective as submitted jobs, but e.g. development needs responsiveness</li> <li>Interactive jobs are high-priority but limited in <code>-n</code> and <code>-t</code></li> <li>Quickly give you a job and logs you in to the compute node</li> <li>Require same Slurm parameters as other jobs</li> </ul>"},{"location":"slurm-intro/#try-interactive","title":"Try interactive","text":"<pre><code>$ interactive -A naiss2023-22-21 -p core -n 1 -t 10:00\n</code></pre> <ul> <li>Which node are you on?</li> <li>Logout with <code>&lt;Ctrl&gt;-D</code> or <code>logout</code></li> </ul>"},{"location":"slurm-intro/#a-simple-job-script-template","title":"A simple job script template","text":"<pre><code>#!/bin/bash -l \n# tell it is bash language and -l is for starting a session with a \"clean environment, e.g. with no modules loaded and paths reset\"\n#SBATCH -A naiss2023-22-21  # Project name\n#SBATCH -p devcore  # Asking for cores (for test jobs and as opposed to multiple nodes) \n#SBATCH -n 1  # Number of cores\n#SBATCH -t 00:10:00  # Ten minutes\n#SBATCH -J Template_script  # Name of the job\n# go to some directory\ncd /proj/introtouppmax/labs\npwd -P\n\n# load software modules\nmodule load bioinfo-tools\nmodule list\n\n# do something\necho Hello world!  </code></pre>"},{"location":"slurm-intro/#how-compute-nodes-are-moved-between-project-clusters","title":"How compute nodes are moved between project clusters","text":"<p>The total job queue, made by putting together job queues of all project clusters, is monitored, and acted upon, by an external program, named meta-scheduler.</p> <p>In short, this program goes over the following procedure, over and over again:</p> <pre><code>Finds out where all the compute nodes are: on a specific project cluster or yet unallocated.\nReads status reports from all compute nodes, about all their jobs, all their compute nodes, and all their active users.\nAre there unallocated compute nodes for all queued jobs?\nOtherwise, try to \"steal\" nodes from project clusters, to get more unallocated compute nodes. This \"stealing\" is done in two steps: a/ \"drain\" a certain node, i.e. disallow more jobs to start on it; b/ remove the compute node from the project cluster, if no jobs are running on the node.\nUse all unallocated nodes to create new compute nodes. Jobs with a higher priority get compute nodes first.\n</code></pre>"},{"location":"slurm-intro/#other-slurm-tools","title":"Other Slurm tools","text":"<ul> <li>Squeue \u2014 quick info about jobs in queue</li> <li>Jobinfo \u2014 detailed info about jobs</li> <li>Finishedjobinfo \u2014 summary of finished jobs</li> <li>Jobstats \u2014 efficiency of booked resources</li> </ul> <p>Objectives</p> <ul> <li>We'll briefly get overviews over <ul> <li>software tools on UPPMAX</li> <li>databases</li> </ul> </li> <li>Introduction quide for installing own software or packages</li> <li>Very short introduction to developing old programs</li> </ul> <p>Keypoints</p> <ul> <li>Centrally installed software are reached through the module system and available throughout all nodes.</li> <li>Your own installed software, scripts, python packages etcetera are available from their paths.</li> <li>You are always in the login node unless you:<ul> <li>start an interactive session</li> <li>start a batch job</li> </ul> </li> <li>Slurm is a job scheduler<ul> <li>add flags to describe your job.</li> </ul> </li> </ul>"},{"location":"slurm/","title":"More about Slurm","text":"<p>Objectives</p> <ul> <li>We'll ...</li> </ul> <p>keypoints</p> <ul> <li>bullet 1</li> <li>bullet 2</li> </ul>"},{"location":"transfer/","title":"Transfering files to/from Bianca","text":"<p>Objectives</p> <ul> <li>We'll go through the methods to tranfer files</li> <li>wharf</li> <li>transit server</li> <li>rsync, scp/sftp</li> <li>pros/cons of different solutions</li> </ul> <p>Warning</p> <p>It is important to keep the entire chain of transfering the data secure</p>"},{"location":"transfer/#how-does-it-work","title":"How does it work?","text":""},{"location":"transfer/#the-wharf","title":"The Wharf","text":"<p>Wharf is a harbour dock</p> <ul> <li>The Wharf area can be reached from both Bianca and any other place on Bianca.</li> <li>Therefore it serves as a bridge between Internet and Bianca.</li> </ul>"},{"location":"transfer/#data-transfers","title":"Data transfers:","text":"<ul> <li>https://www.uppmax.uu.se/support/user-guides/bianca-user-guide/ <ul> <li>section 3: Transfer files to and from Bianca</li> </ul> </li> </ul>"},{"location":"transfer/#the-wharf-location","title":"The wharf location","text":"<ul> <li> <p>The path to this folder, once you are logged into your project's cluster, is:</p> <p>/proj//nobackup/wharf//- E.g. /proj/sens2016999/nobackup/wharf/myuser/myuser-sens2016999 <li> <p>To transfer data from Bianca, copy the files you want to transfer here</p> </li> <li> <p>To get the files transfered to the wharf area from outside, move the files to you project folde or home folder.</p> </li> <li> <p>Please note that in the wharf you only have access to upload your files to the directory that is named:    -    e.g.    myuser-sens2016999"},{"location":"transfer/#_1","title":"Transfering files to/from Bianca","text":"<p>b.  Second step is from a computer outside of Bianca.  c.  Using standard sftp client d.  Some other sftp client e.  Mounting the sftp-server with sshfs f.  Bulk recursive transfer with only standard sftp client g.  Transit Server</p>"},{"location":"transfer/#first-steps","title":"First steps","text":""},{"location":"transfer/#using-standard-sftp-client-commandline","title":"Using standard sftp client (commandline)","text":"<pre><code>$ sftp -q &lt;username&gt;-&lt;projid&gt;@bianca-sftp.uppmax.uu.se\nEx.\n$ sftp -q myuser-sens2016999@bianca-sftp.uppmax.uu.se\n</code></pre> <p>Notice the different host name!</p> <p>The -q flag is to be quiet (not showing the banner intended to help someone trying to ssh to the host), if your client does not support it, you can just skip it.</p> <p>As password you use your normal UPPMAX password directly followed by the six digits from the second factor application from step 1.</p> <p>Ex. if your password is \"VerySecret\" and the second factor code is 123 456 you would type VerySecret123456 as the password in this step.</p> <p>Once connected you will have to type the sftp commands to upload/download files. Have a look at the Basic SFTP commands guide to get started with it.</p> <p>Please note that in the wharf you only have access to upload your files to the directory that is named:</p> <p>- e.g. myuser-sens2016999 <p>so you will want to cd to that directory the first thing you do.</p> <p>sftp&gt; cd myuser-sens2016999</p> <p>Alternatively, you can specify this at the end of the sftp command, so that you will always end up in the correct folder directly.</p> <p>$ sftp -q -@bianca-sftp.uppmax.uu.se:- E.g. $ sftp -q myuser-sens2016999@bianca-sftp.uppmax.uu.se:myuser-sens2016999 <p>sftp supports a recursive flag (put -r), but it seems to be very sensitive to combinations of different sftp servers and clients, so be warned... a bit further down you can see a rough solution for bulk transfers.</p>"},{"location":"transfer/#some-other-sftp-client","title":"Some other sftp client","text":"<p>Please notice that sftp is NOT the same as scp. So be sure to really use a sftp client -- not just a scp client.</p> <p>Also be aware that many sftp clients use reconnects (with a cached version of your password). This will not work for Bianca, because of the second factor! And some try to use multiple connections with the same password, which will fail.</p> <p>So for example with lftp, you need to \"set net:connection_limit 1\". lftp may also defer the actual connection until it's really required unless you end your connect URL with a path.</p> <p>An example command line for lftp would be</p> <p>lftp sftp://-@bianca-sftp.uppmax.uu.se/-/"},{"location":"transfer/#mounting-the-sftp-server-with-sshfs-on-you-local-machine","title":"Mounting the sftp-server with sshfs on you local machine","text":"<p>Mount the wharf on your machine</p> <ul> <li>This is only possible on your own system. </li> <li>sshfs allows you to mount the wharf on your own machine. </li> <li>You will be able to copy and work on the data using your own local tools such as cp or vim. </li> <li>Remember that you are neither logged in on the distant server, nor is the data physically on your local disk (until you have copied it).</li> </ul> <p>Warning</p> <p>UPPMAX doesn't have sshfs client package installed for security reasons. sshfs is available on most Linux distributions: install the package sshfs on Ubuntu, fuse-sshfs on Fedora, RHEL7/CentOS7 (enable EPEL repository) and RHEL8 (enable codeready-builder repository) / CentOS8 (enable powertools repository).    </p>"},{"location":"transfer/#bulk-recursive-transfer-with-only-standard-sftp-client","title":"Bulk recursive transfer with only standard sftp client","text":"<ul> <li>It seems to be rather common with directory structures with symbolic links inside the directories that you should transfer. </li> <li>This is a very simple solution to copy everything in a specific folder (and follow symbolic links) to the wharf.</li> </ul> <p>============== ~/sftp-upload.sh ==============</p>"},{"location":"transfer/#binbash","title":"!/bin/bash","text":""},{"location":"transfer/#sftp-uploadsh","title":"sftp-upload.sh","text":"<p>find $ -type d | awk '{print \"mkdir\",\"\\\"\"$0\"\\\"\"}'  find $ -type f | awk '{print \"put\",\"\\\"\"$0\"\\\"\",\"\\\"\"$0\"\\\"\" }'  find $* -type l | awk '{print \"put\",\"\\\"\"$0\"\\\"\",\"\\\"\"$0\"\\\"\" }' </p> <p>With this script you can do:</p> <p>cd /home/myuser/glob/testing/nobackup/somedata ~/sftp-upload.sh *|sftp -oBatchMode=no -b- -@bianca-sftp.uppmax.uu.se:- <p>The special \"-b\" makes the script stop on error.</p>"},{"location":"transfer/#transit","title":"Transit","text":"<p>Recommended way from Rackham? - To facilitate secure data transfers to, from and within the system for computing on sensitive data (bianca/castor) a service is available via ssh at transit.uppmax.uu.se. - You can connect to transit via ssh. Once connected, you should see a short help message. The most important thing there is the mount_wharf command which you can use to mount a project from the bianca wharf</p> <p>*More...</p>"},{"location":"transfer/#ngi-deliver","title":"NGI Deliver","text":"<ul> <li>Not covered here but </li> <li>https://www.uppmax.uu.se/support/user-guides/deliver-user-guide/</li> <li>https://www.uppmax.uu.se/support/user-guides/grus-user-guide/</li> </ul> <p>keypoints</p> <ul> <li>The \"WHARF\" works like a dock at the harbour.</li> <li>There are several ways to use the wharf to tranfer files<ul> <li>copy</li> <li>transit server</li> <li>rsync, scp/sftp</li> </ul> </li> </ul>"}]}